import pandas as pd
import pdb
import time
from tqdm import tqdm
import matplotlib.pyplot as plt
import jieba 
from collections import Counter
from wordcloud import WordCloud, STOPWORDS


MY_WECHAT_NAME = "ä½ çš„å¾®ä¿¡æ˜µç§°"    # ç”¨æ¥æ›¿ä»£èŠå¤©è®°å½•æ–‡ä»¶ä¸­çš„ã€æˆ‘ã€‘ 
# ä¸€äº›æ— èŠçš„åˆ†è¯ï¼Œä¸å‡ºç°åœ¨è¯äº‘ä¸­
MY_STOPWORDS = ["ä¸€ä¸ª", "è¿™ä¸ª", "çœŸçš„", "å¯ä»¥", "å°±æ˜¯", "æ²¡æœ‰", "ä¸æ˜¯", "æˆ‘ä»¬", "è¿˜æ˜¯", "ç°åœ¨", "åº”è¯¥", "ä»€ä¹ˆ", "å¯èƒ½", "è¿™ä¹ˆ", "ä»–ä»¬", "é‚£ä¸ª", "çŸ¥é“", "æ„Ÿè§‰",
                "å·²ç»", "ä½†æ˜¯", "ä¸ä¼š", "è§‰å¾—", "å¥½åƒ", "æ€ä¹ˆ", "è¿˜æœ‰", "å“ˆå“ˆå“ˆå“ˆ", "æ˜å¤©", "ä½ ä»¬", "ä¸€ä¸‹", "æ¶ˆæ¯", "ä¸èƒ½", "ä»Šå¤©", "è€Œä¸”", "ä¸€æ¡", "å¼€å§‹", "ç›´æ¥", 
                "æ’¤å›", "å¦‚æœ", "ä¹‹å‰", "æ˜¯ä¸æ˜¯", "æ‰€ä»¥", "å› ä¸º", "çš„è¯", "ç„¶å", "æ—¶å€™", "è¿™ç§", "ä¸ºå•¥", "çœ‹åˆ°", "æœ‰ç‚¹", "æ—¶é—´", "æœ€å", "ç”šè‡³", 
                "\r\n", "ä¹‹è„‘", "æ•°å­—", "éœ€è¦", "ä¹‹å", "ä¸€äº›", "æ™šä¸Š", "ä¸‹åˆ", "å¿…é™", "å¤§å®¶", "å¤§æ¦‚", "å¿…é™ä»»", "æ¯”è¾ƒ", "30", 
                "ä»Šæ™š", "è¿™è¾¹", "æˆ–è€…", "å‡ºæ¥", "11", "é‚£è¾¹", "", "", "", "", "", "", "", "", "", "", "", "", "", ]


def remove_useless_msg(x: str):
    if pd.isna(x):
        return False
    for black in ['<msg', '<?xml', 'http', '<a']:
        if x.startswith(black):
            return False
    return True


def load_info(contacts_file: str = 'contacts.csv', 
                  messages_file: str = 'messages.csv'):
    global contacts, messages
    start_date = "2023-01-01"
    end_date = "2023-12-30"
    
    contacts = pd.read_csv(contacts_file, index_col=False)
    isgroup = {}
    for i, row in contacts.iterrows():
        isgroup[row['NickName']] = 'chatroom' in row['UserName']
    messages = pd.read_csv(messages_file, index_col=False)
    messages["isGroup"] = messages["NickName"].apply(lambda x: isgroup[x])
    messages = messages[messages["StrContent"].apply(remove_useless_msg)]
    messages = messages[(messages["StrTime"] >= start_date) & (messages["StrTime"] < end_date)]
    messages["NickName"] = messages["NickName"].apply(str)
    messages = messages.reset_index()
    return contacts, messages

def remark2name(remark: str):
    global contacts
    if remark == "æˆ‘":
        return MY_WECHAT_NAME
    res = contacts[contacts["Remark"] == remark]["NickName"].values
    return res[0] if len(res) > 0 else remark

def filter_group(df: pd.DataFrame, group_name: str):
    res = df[df["NickName"].apply(lambda x: group_name in x)]
    fullname = res["NickName"].value_counts().index[0]
    filtered = res[res["NickName"] == fullname]
    filtered = filtered.reset_index()
    return filtered, fullname


def calculate_words(df: pd.DataFrame):
    n_mess = len(df)
    n_char = sum(df['StrContent'].apply(len))
    return n_mess, n_char
    
def get_latest_time(df: pd.DataFrame, latest_hour: float = 5):
    def score(x):
        hour, min, sec = time.localtime(x)[3:6]
        if hour < latest_hour:
            hour += 24
        return hour * 3600 + min * 60 + sec

    late_score = df['CreateTime'].apply(score)
    latest = df.iloc[late_score.idxmax()]
    return latest


def plot_nmess_per_minute(df: pd.DataFrame):
    hours = df.CreateTime.apply(lambda x: int(time.strftime("%H", time.localtime(x))))
    minutes = df.CreateTime.apply(lambda x: int(time.strftime("%M", time.localtime(x))))
    df["time"] = hours + minutes / 60
    plt.figure(figsize=(12, 4))
    df["time"].plot.hist(bins=1440, alpha=0.5)
    plt.title("Distribution of messages per minute")
    plt.xticks(range(0, 25, 1))
    plt.savefig("nmess_per_minute.png")
    
def plot_nmess_per_month(df: pd.DataFrame):
    months = df.CreateTime.apply(lambda x: int(time.strftime("%m", time.localtime(x))))
    plt.figure(figsize=(12, 4))
    months.value_counts().sort_index().plot.bar()
    plt.title("Distribution of messages per month")
    plt.savefig("nmess_per_month.png")


def plot_wordcloud(df):
    global STOPWORDS
    all_words = []
    STOPWORDS |= set(MY_STOPWORDS)
    for i, row in tqdm(df.iterrows(), total=len(df)):
        words = jieba.lcut(row["StrContent"])
        for word in words:
            if len(word) > 1 and word not in STOPWORDS:
                all_words.append(word)
    cnt = sorted(Counter(all_words).items(), key=lambda x: x[1], reverse=True)
    text = " ".join(all_words)
    wc = WordCloud(font_path="simhei.ttf", background_color="white", max_words=2000,
                   stopwords=STOPWORDS, max_font_size=200, min_font_size=6,
                   width=1080, height=720, random_state=42,
                   repeat=False, collocations=False, )
    wc.generate(text)
    plt.figure(figsize=(12, 12))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    plt.savefig("wordcloud.png")
    return cnt
    
def most_active_person_in_group(df: pd.DataFrame, topk: int = 3):
    vc = df["Sender"].value_counts()
    name, n_mess = vc.index, vc.values
    results = []
    for i in range(topk):
        n_char = sum(df[df["Sender"] == name[i]]["StrContent"].apply(len))
        results.append((remark2name(name[i]), n_mess[i], n_char))
    return results


def most_active_day(df):
    ymd = df['CreateTime'].apply(lambda x: time.strftime("%Y-%m-%d", time.localtime(x)))
    days = ymd.value_counts()
    return days.value_counts().sort_index().idxmax()

def top_emoji(df: pd.DataFrame):
    import re
    cnt = {}
    for i, row in df.iterrows():
        res_all = re.findall("\[.*?\]", row["StrContent"], re.I|re.M)
        for res in res_all:
            if len(res) < 10:
                cnt[res] = cnt.get(res, 0) + 1
    cnt = sorted(cnt.items(), key=lambda x: x[1], reverse=True)
    return cnt


def personal_annual_report():
    global messages
    me = messages[messages['Sender'] == 'æˆ‘']
    me = me.reset_index()
    n_mess, n_char = calculate_words(me)
    latest = get_latest_time(me)
    cnt = plot_wordcloud(me)
    
    print(f"\nğŸ‘ä¸ªäººå¾®ä¿¡2023å¹´åº¦æŠ¥å‘Š\n")
    print("ğŸ“Šè¿™ä¸€å¹´ä¸­æˆ‘æ€»å…±ç»™{}ä¸ªç¾¤èŠå’Œ{}ä¸ªè”ç³»äººå‘äº†{}æ¡æ¶ˆæ¯ï¼Œå…±è®¡{}ä¸ªå­—ã€‚".format(
        len(me[me["isGroup"] == True]["NickName"].unique()), 
        len(me[me["isGroup"] == False]["NickName"].unique()), 
        n_mess, n_char), end="")
    to = "ç¾¤èŠ" if latest["isGroup"] else "è”ç³»äºº"
    print("å…¶ä¸­æœ€æ™šçš„ä¸€æ¡æ¶ˆæ¯æ˜¯åœ¨ã€{}ã€‘å‘ç»™{}ã€Œ{}ã€çš„ï¼Œå†…å®¹æ˜¯ã€Œ{}ã€\n".format(
        latest["StrTime"], to, latest["NickName"], latest["StrContent"]))
    
    day_cnt = me["CreateTime"].apply(lambda x: time.strftime("%Yå¹´%mæœˆ%dæ—¥", time.localtime(x))).value_counts()
    print("\nğŸ“…ã€{}ã€‘è¿™ä¸€å¤©ä¸€å®šå¾ˆç‰¹åˆ«ï¼Œæˆ‘ç–¯ç‹‚å‘é€äº†{}æ¡å¾®ä¿¡ã€‚ç›¸æ¯”ä¹‹ä¸‹ã€{}ã€‘å°±æ˜¾å¾—å¾ˆå®‰é™ï¼Œåªå‘äº†{}æ¡æ¶ˆæ¯ã€‚\n".format(
        day_cnt.index[0], day_cnt.values[0], day_cnt.index[-1], day_cnt.values[-1]))
    
    group_cnt = me[me["isGroup"] == True]["NickName"].value_counts()
    private_cnt = me[me["isGroup"] == False]["NickName"].value_counts()
    print("ğŸ‘‰æˆ‘æœ€å–œæ¬¢åœ¨ç¾¤èŠã€{}ã€‘å‘è¨€ï¼Œè´¡çŒ®äº†{}æ¡æ²¡ä»€ä¹ˆä»·å€¼çš„èŠå¤©è®°å½•ã€‚".format(
        group_cnt.index[0], group_cnt.values[0]))
    print("ğŸ‘‰æˆ‘æœ€å–œæ¬¢å’Œè”ç³»äººã€{}ã€‘èŠå¤©ï¼Œå‘taæ¿€æƒ…å‘å‡º{}æ¡ä¿¡æ¯ï¼Œå¾—åˆ°äº†{}æ¡å›å¤ã€‚\n".format(
        private_cnt.index[0], private_cnt.values[0], 
        len(messages[(messages["NickName"] == private_cnt.index[0]) & (messages["Sender"] != 'æˆ‘')])))

    print("\nğŸ”¥æˆ‘çš„å¹´åº¦çƒ­è¯Top5ï¼š")
    emojis = ["1ï¸âƒ£", "2ï¸âƒ£", "3ï¸âƒ£", "4ï¸âƒ£", "5ï¸âƒ£"]
    for i in range(5):
        print("{}ã€{}ã€‘å…±ä½¿ç”¨{}æ¬¡".format(emojis[i], cnt[i][0], cnt[i][1]))
    
    emojis = top_emoji(me)
    print("\nğŸ¤šæˆ‘çš„å¹´åº¦è¡¨æƒ…åŒ…Top5:")
    for i in range(5):
        print("{}".format(emojis[i][0]), end=" ")
    
    plot_nmess_per_minute(me)
    plot_nmess_per_month(me)
    
    print("\n\n")

def group_chat_annual_report(groupname):
    global messages
    group, fullname = filter_group(messages, groupname)
    n_mess, n_char = calculate_words(group)
    latest = get_latest_time(group)
    cnt = plot_wordcloud(group)
    print(len(cnt[0][0]), cnt[0][0])
    print(f"ğŸ‘ç¾¤èŠã€{fullname}ã€‘2023å¹´åº¦æŠ¥å‘Š\n")
    print("ğŸ“Šè¿™ä¸€å¹´ä¸­ï¼Œæˆ‘ä»¬åœ¨ç¾¤é‡Œä¸€å…±å‘å‡ºäº†{}æ¡æ¶ˆæ¯ï¼Œ{}ä¸ªå­—".format(n_mess, n_char))
    print("  å…¶ä¸­æœ€æ™šçš„ä¸€æ¡æ¶ˆæ¯æ˜¯ã€{}ã€‘åœ¨ã€{}ã€‘å‘å‡ºçš„ï¼Œå†…å®¹æ˜¯ã€{}ã€‘".format(
        remark2name(latest["Sender"]), latest["StrTime"], latest["StrContent"]))
    
    actives = most_active_person_in_group(group)
    print("\nğŸ™‹â€â™‚ï¸æœ¬ç¾¤æ°´ç¾¤å°èƒ½æ‰‹æ’è¡Œï¼š")
    print("  ğŸ¥‡ã€{}ã€‘äº§å‡ºäº†{}æ¡æ¶ˆæ¯ï¼Œ å…±{}ä¸ªå­—çš„åºŸè¯".format(actives[0][0], actives[0][1], actives[0][2]))
    print("  ğŸ¥ˆã€{}ã€‘äº§å‡ºäº†{}æ¡æ¶ˆæ¯ï¼Œ å…±{}ä¸ªå­—çš„åºŸè¯".format(actives[1][0], actives[1][1], actives[1][2]))
    print("  ğŸ¥‰ã€{}ã€‘äº§å‡ºäº†{}æ¡æ¶ˆæ¯ï¼Œ å…±{}ä¸ªå­—çš„åºŸè¯".format(actives[2][0], actives[2][1], actives[2][2]))
    
    print("\nğŸ”¥æœ¬ç¾¤å¹´åº¦çƒ­è¯Top5ï¼š")
    emojis = ["1ï¸âƒ£", "2ï¸âƒ£", "3ï¸âƒ£", "4ï¸âƒ£", "5ï¸âƒ£"]
    for i in range(5):
        print("{}ã€{}ã€‘å…±å‡ºç°äº†{}æ¬¡".format(emojis[i], cnt[i][0], cnt[i][1]))
    
    emojis = top_emoji(group)
    print("\nğŸ¤šæœ¬ç¾¤å¹´åº¦è¡¨æƒ…åŒ…Top5:")
    for i in range(5):
        print("{}".format(emojis[i][0]), end=" ")
    
    plot_nmess_per_minute(group)    
    plot_nmess_per_month(group)
    
def private_chat_annual_report(name):
    # TODO: ç”Ÿæˆå’ŒæŸä¸ªäººçš„èŠå¤©ä¿¡æ¯æŠ¥å‘Š
    # å»è·¨å¹´æ—…æ¸¸æ‡’å¾—å†™äº†ï¼Œæ¬¢è¿å¤§ä½¬æäº¤PRğŸ‘
    pass
    
    
if __name__ == "__main__":
    contacts, messages = load_info()
    personal_annual_report()
    group_chat_annual_report("ç¾¤èŠåç§°")